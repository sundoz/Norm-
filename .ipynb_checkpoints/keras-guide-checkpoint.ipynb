{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()  # shape = (samples, ...) -> (60000, 28, 28)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "# (0, 0, 0, 0, 1, 0, 0) - one hot encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Dense(128, input_shape=(784, ), activation='relu'))\n",
    "#model.add(Dense(256, input_shape=(784, ), activation='relu'))\n",
    "model.add(Dense(10, input_shape=(784, ), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sundoz\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.7854 - acc: 0.7437 - val_loss: 0.5745 - val_acc: 0.8106\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.5332 - acc: 0.8225 - val_loss: 0.5051 - val_acc: 0.8309\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4873 - acc: 0.8368 - val_loss: 0.4818 - val_acc: 0.8350\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4628 - acc: 0.8436 - val_loss: 0.4617 - val_acc: 0.8425\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.4463 - acc: 0.8486 - val_loss: 0.4531 - val_acc: 0.8462\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4363 - acc: 0.8518 - val_loss: 0.4491 - val_acc: 0.8438\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4286 - acc: 0.8543 - val_loss: 0.4464 - val_acc: 0.8447\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4212 - acc: 0.8565 - val_loss: 0.4375 - val_acc: 0.8490\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4152 - acc: 0.8576 - val_loss: 0.4298 - val_acc: 0.8530\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4103 - acc: 0.8587 - val_loss: 0.4306 - val_acc: 0.8547\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.4071 - acc: 0.8603 - val_loss: 0.4324 - val_acc: 0.8499\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.4029 - acc: 0.8611 - val_loss: 0.4309 - val_acc: 0.8501\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.4011 - acc: 0.8615 - val_loss: 0.4218 - val_acc: 0.8548\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3970 - acc: 0.8639 - val_loss: 0.4185 - val_acc: 0.8552\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3953 - acc: 0.8624 - val_loss: 0.4186 - val_acc: 0.8547\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3922 - acc: 0.8646 - val_loss: 0.4194 - val_acc: 0.8562\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3900 - acc: 0.8660 - val_loss: 0.4150 - val_acc: 0.8586\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3888 - acc: 0.8647 - val_loss: 0.4175 - val_acc: 0.8547\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3875 - acc: 0.8659 - val_loss: 0.4198 - val_acc: 0.8554\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3849 - acc: 0.8671 - val_loss: 0.4153 - val_acc: 0.8564\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3839 - acc: 0.8667 - val_loss: 0.4110 - val_acc: 0.8585\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3824 - acc: 0.8680 - val_loss: 0.4103 - val_acc: 0.8579\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3807 - acc: 0.8663 - val_loss: 0.4151 - val_acc: 0.8568\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3790 - acc: 0.8678 - val_loss: 0.4154 - val_acc: 0.8570\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3782 - acc: 0.8686 - val_loss: 0.4126 - val_acc: 0.8566\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3776 - acc: 0.8682 - val_loss: 0.4159 - val_acc: 0.8556\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.3760 - acc: 0.8684 - val_loss: 0.4105 - val_acc: 0.8607\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - ETA: 0s - loss: 0.3743 - acc: 0.870 - 1s 25us/step - loss: 0.3741 - acc: 0.8702 - val_loss: 0.4123 - val_acc: 0.8559\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3742 - acc: 0.8692 - val_loss: 0.4141 - val_acc: 0.8548\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3729 - acc: 0.8692 - val_loss: 0.4087 - val_acc: 0.8588\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.3719 - acc: 0.8706 - val_loss: 0.4141 - val_acc: 0.8573\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.3713 - acc: 0.8700 - val_loss: 0.4099 - val_acc: 0.8575\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3709 - acc: 0.8709 - val_loss: 0.4076 - val_acc: 0.8576\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3698 - acc: 0.8708 - val_loss: 0.4112 - val_acc: 0.8595\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3694 - acc: 0.8706 - val_loss: 0.4163 - val_acc: 0.8562\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.3689 - acc: 0.8705 - val_loss: 0.4093 - val_acc: 0.8587\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3676 - acc: 0.8720 - val_loss: 0.4110 - val_acc: 0.8584\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3673 - acc: 0.8720 - val_loss: 0.4109 - val_acc: 0.8577\n",
      "Epoch 39/50\n",
      "28672/48000 [================>.............] - ETA: 0s - loss: 0.3698 - acc: 0.8710"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4417081566810608, 0.848]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overfitting\n",
    " - высокая точность на тренировочном мн-ве\n",
    " - низакая на валидационное \n",
    "\n",
    "# underfitting\n",
    " - точность на валидационное выше чем на тренировочном \n",
    "\n",
    "\n",
    "# fine-tuning\n",
    "    -меняем параметры обучения для достижения лучшей точности "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
